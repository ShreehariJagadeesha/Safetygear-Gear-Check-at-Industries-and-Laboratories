{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1088 images belonging to 2 classes.\n",
      "{'fail': 0, 'pass': 1}\n",
      "Found 461 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 25s 8s/step - loss: 1.0424 - accuracy: 0.5344 - val_loss: 0.6762 - val_accuracy: 0.5547\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 17s 6s/step - loss: 0.7072 - accuracy: 0.5186 - val_loss: 0.6594 - val_accuracy: 0.8750\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 18s 7s/step - loss: 0.6547 - accuracy: 0.6605 - val_loss: 0.5964 - val_accuracy: 0.8125\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 17s 7s/step - loss: 0.6237 - accuracy: 0.6464 - val_loss: 0.7528 - val_accuracy: 0.4375\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 17s 6s/step - loss: 0.6900 - accuracy: 0.5504 - val_loss: 0.4892 - val_accuracy: 0.8281\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 18s 6s/step - loss: 0.5420 - accuracy: 0.7656 - val_loss: 0.4596 - val_accuracy: 0.7578\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 20s 7s/step - loss: 0.6563 - accuracy: 0.6582 - val_loss: 0.4703 - val_accuracy: 0.7969\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 18s 7s/step - loss: 0.4930 - accuracy: 0.7581 - val_loss: 0.3363 - val_accuracy: 0.8438\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 18s 6s/step - loss: 0.4808 - accuracy: 0.7627 - val_loss: 0.3712 - val_accuracy: 0.8047\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 18s 6s/step - loss: 0.4889 - accuracy: 0.7376 - val_loss: 0.3862 - val_accuracy: 0.8594\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 18s 6s/step - loss: 0.4489 - accuracy: 0.7803 - val_loss: 0.2911 - val_accuracy: 0.8672\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 18s 6s/step - loss: 0.7635 - accuracy: 0.6911 - val_loss: 0.3752 - val_accuracy: 0.8672\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 17s 6s/step - loss: 0.4651 - accuracy: 0.7842 - val_loss: 0.3573 - val_accuracy: 0.8203\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 19s 7s/step - loss: 0.4426 - accuracy: 0.7786 - val_loss: 0.3261 - val_accuracy: 0.8359\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 18s 6s/step - loss: 0.4031 - accuracy: 0.8161 - val_loss: 0.2069 - val_accuracy: 0.9453\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 18s 6s/step - loss: 0.4048 - accuracy: 0.8258 - val_loss: 0.3643 - val_accuracy: 0.8047\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 18s 7s/step - loss: 0.4180 - accuracy: 0.7969 - val_loss: 0.6410 - val_accuracy: 0.6875\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 16s 5s/step - loss: 0.4575 - accuracy: 0.7810 - val_loss: 0.2821 - val_accuracy: 0.8594\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 17s 6s/step - loss: 0.3449 - accuracy: 0.8576 - val_loss: 0.3624 - val_accuracy: 0.7969\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 19s 7s/step - loss: 0.4846 - accuracy: 0.7946 - val_loss: 0.2518 - val_accuracy: 0.8828\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K\n",
    "from time import time\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "\n",
    "# dimensions of our images.\n",
    "img_width, img_height = 150, 150\n",
    "\n",
    "train_data_dir = r'C:\\Users\\sjagade7\\Desktop\\Clg stuff\\Git Repositories\\image_classifier\\data\\train'\n",
    "validation_data_dir = r'C:\\Users\\sjagade7\\Desktop\\Clg stuff\\Git Repositories\\image_classifier\\data\\validation'\n",
    "nb_train_samples = 500\n",
    "nb_validation_samples = 200\n",
    "epochs = 200\n",
    "batch_size = 64\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, img_width, img_height)\n",
    "else:\n",
    "    input_shape = (img_width, img_height, 3)\n",
    "\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', # or categorical_crossentropy\n",
    "              optimizer='rmsprop',# or adagrad\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "tensorboard_callback = TensorBoard(log_dir=r'C:\\Users\\sjagade7\\Desktop\\Clg stuff\\Git Repositories\\image_classifier\\graphs')\n",
    "\n",
    "\n",
    "# this is the augmentation configuration we will use for testing:\n",
    "# only rescaling\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "\n",
    "print(train_generator.class_indices)\n",
    "\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "\n",
    "history=model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=nb_train_samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    callbacks=[tensorboard_callback],\n",
    "    validation_steps=nb_validation_samples // batch_size\n",
    "    )\n",
    "\n",
    "\n",
    "#plt.plot(history.history['acc'])\n",
    "#plt.plot(history.history['val_acc'])\n",
    "#plt.title('model accuracy')\n",
    "#plt.ylabel('accuracy')\n",
    "#plt.xlabel('epoch')\n",
    "#plt.legend(['train', 'val'], loc='upper left')\n",
    "#plt.show()\n",
    "\n",
    "\n",
    "#plt.plot(history.history['loss'])\n",
    "#plt.plot(history.history['val_loss'])\n",
    "#plt.title('model loss')\n",
    "#plt.ylabel('loss')\n",
    "#plt.xlabel('epoch')\n",
    "#plt.legend(['train', 'val'], loc='upper left')\n",
    "#plt.show()\n",
    "\n",
    "    \n",
    "    \n",
    "model.save('model.h5')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['9.jpg']\n",
      "open the gate\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "\n",
    "\n",
    "# dimensions of our images\n",
    "img_width, img_height = 150, 150\n",
    "\n",
    "# load the model we saved\n",
    "model = load_model('model.h5')\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "mypath = r'C:\\Users\\sjagade7\\Desktop\\Clg stuff\\Git Repositories\\image_classifier\\predict//'\n",
    "onlyfiles = [f for f in listdir(mypath) if isfile(join(mypath, f))]\n",
    "print(onlyfiles)\n",
    "# predicting images\n",
    "fail_counter = 0 \n",
    "pass_counter  = 0\n",
    "for file in onlyfiles:\n",
    "    img = image.load_img(mypath+file, target_size=(img_width, img_height))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    \n",
    "    images = np.vstack([x])\n",
    "    classes = model.predict_classes(images, batch_size=10)\n",
    "    classes = classes[0][0]\n",
    "    \n",
    "if classes == 0:\n",
    "            print('gate closed')\n",
    "            print('reporting issue to concerned manager')\n",
    "else:\n",
    "            print('open the gate')\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
